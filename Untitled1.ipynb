{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import parallel_coordinates\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics  import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['データ内連番', '球種', '投球位置区域', '年度', '試合ID', '試合内連番', '試合内投球数', '日付', '時刻',\n",
      "       'ホームチームID', 'アウェイチームID', '球場ID', '球場名', '試合種別詳細', 'イニング', '表裏',\n",
      "       'イニング内打席数', '打席内投球数', '投手ID', '投手チームID', '投手投球左右', '投手役割', '投手登板順',\n",
      "       '投手試合内対戦打者数', '投手試合内投球数', '投手イニング内投球数', '打者ID', '打者チームID', '打者打席左右',\n",
      "       '打者打順', '打者守備位置', '打者試合内打席数', 'プレイ前ホームチーム得点数', 'プレイ前アウェイチーム得点数',\n",
      "       'プレイ前アウト数', 'プレイ前ボール数', 'プレイ前ストライク数', 'プレイ前走者状況', '一塁走者ID', '二塁走者ID',\n",
      "       '三塁走者ID', '捕手ID', '一塁手ID', '二塁手ID', '三塁手ID', '遊撃手ID', '左翼手ID', '中堅手ID',\n",
      "       '右翼手ID', '成績対象投手ID', '成績対象打者ID'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    120396\n",
       "2     47774\n",
       "4     21344\n",
       "1     19213\n",
       "3     18161\n",
       "5     13940\n",
       "7     13368\n",
       "6      2921\n",
       "Name: 球種, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 200)\n",
    "train_pitch_df = pd.read_csv(\"../Data/train_pitch.csv\")\n",
    "train_player_df = pd.read_csv(\"../Data/train_player.csv\")\n",
    "\n",
    "print(train_pitch_df.columns)\n",
    "train_pitch_df.head()\n",
    "\n",
    "#one-hot化が必要\n",
    "\n",
    "columns1 = ['球場名','試合種別詳細','イニング','表裏','打者打席左右',\n",
    "            '投手投球左右','投手役割','投手登板順','打者打順', '打者守備位置']\n",
    "\n",
    "#one-hot化が必要だが多いので保留\n",
    "columns2 = ['日付', '時刻','年度','試合ID','投手ID','投手チームID','打者ID','打者チームID','プレイ前走者状況',\n",
    "            '一塁走者ID', '二塁走者ID','三塁走者ID', '捕手ID', '一塁手ID', '二塁手ID', '三塁手ID', '遊撃手ID',\n",
    "            '左翼手ID', '中堅手ID','右翼手ID', '成績対象投手ID', '成績対象打者ID','ホームチームID','アウェイチームID','球場ID']\n",
    "\n",
    "#one-hot化が必要なし\n",
    "columns3 = ['試合内連番', '試合内投球数','イニング内打席数', '打席内投球数','投手試合内対戦打者数', '投手試合内投球数',\n",
    "            '投手イニング内投球数','打者試合内打席数', 'プレイ前ホームチーム得点数', 'プレイ前アウェイチーム得点数',\n",
    "            'プレイ前アウト数', 'プレイ前ボール数', 'プレイ前ストライク数']\n",
    "\n",
    "columns4 = ['データ内連番','球種','投球位置区域']\n",
    "\n",
    "key = ['データ内連番']\n",
    "y1 = ['球種'] #目的変数１\n",
    "y2 = ['投球位置区域'] #目的変数２\n",
    "\n",
    "#読み込み\n",
    "train_pitch_df = pd.read_csv(\"../Data/train_pitch.csv\")\n",
    "\n",
    "#指定cloumnのone-hot化\n",
    "train_pitch_df = pd.get_dummies(train_pitch_df, columns = columns1)\n",
    "\n",
    "#余分な特徴量を削除\n",
    "train_pitch_df2 = train_pitch_df.drop(columns = columns2)\n",
    "X = train_pitch_df2.drop(columns = columns4)\n",
    "\n",
    "Y = train_pitch_df['球種']\n",
    "Y2 = train_pitch_df['球種'].astype(str)\n",
    "Y2 = pd.get_dummies(Y2)\n",
    "\n",
    "X.head()\n",
    "\n",
    "#要素ごとの個数を表示\n",
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "2921\n",
      "10000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "#要素の偏りをなくしたデータセットの作成\n",
    "\n",
    "Y_X = pd.concat([Y,X],axis = 1)\n",
    "Y_X0 = Y_X[Y_X['球種'] == 0]\n",
    "Y_X_10000 = pd.DataFrame()\n",
    "for i in range(8):\n",
    "    tmp = Y_X[Y_X['球種'] == i]\n",
    "    if len(tmp) > 10000:\n",
    "        tmp = tmp[:10000]\n",
    "    else:\n",
    "        tmp = tmp[:len(tmp)]\n",
    "    print(len(tmp))\n",
    "    Y_X_10000 = pd.concat([Y_X_10000, tmp])\n",
    "\n",
    "len(Y_X_10000)\n",
    "X2 = Y_X_10000.drop(columns = [\"球種\"])\n",
    "Y2 = Y_X_10000[\"球種\"]\n",
    "\n",
    "#相関係数\n",
    "Y_X_corr = Y_X.corr()\n",
    "print(type(Y_X_corr))\n",
    "\n",
    "#相関係数のソート\n",
    "#200行まで表示\n",
    "pd.set_option('display.max_rows',200)\n",
    "Y_X_corr_rank = Y_X_corr['球種']\n",
    "Y_X_corr_rank = Y_X_corr.sort_values('球種',ascending=False)\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Optimization\n",
      "---------------------------------\n",
      "Inital_Design:1 / 1  Try:0 / 1\n",
      "\n",
      "Next bounds is\n",
      "eta = 0.338  max_depth = 10.595  min_child_weight = 1.051  subsample = 0.995  colsample_bytree = 0.876  gamma = 3.823  n_estimators = 63.589  learning_rate = 0.252  reg_lambda = 0.858  reg_alpha = 0.048  \n",
      "\n",
      "Logloss: nan\n",
      "---------------------------------\n",
      "Inital_Design:1 / 1  Try:1 / 1\n",
      "\n",
      "Next bounds is\n",
      "eta = 0.375  max_depth = 11.393  min_child_weight = 0.282  subsample = 0.944  colsample_bytree = 0.939  gamma = 8.837  n_estimators = 84.375  learning_rate = 0.864  reg_lambda = 0.854  reg_alpha = 0.195  \n",
      "\n",
      "Logloss: nan\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "########### XGBoost ###########\n",
    "import xgboost as xgb\n",
    "import GPy\n",
    "import GPyOpt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "'''\n",
    "X：特徴量\n",
    "Y：目的変数\n",
    "必要なもの\n",
    "pip install xgboost\n",
    "pip install japanize-matplotlib\n",
    "'''\n",
    "#通常\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.3, shuffle=True)\n",
    "\n",
    "#球種割合揃え\n",
    "#train_x, test_x, train_y, test_y = train_test_split(X2, Y2, test_size=0.3, shuffle=True)\n",
    "\n",
    "\n",
    "init_num = 1          #初期サンプル数\n",
    "max_iter = 1          #サンプリング回数\n",
    "\n",
    "#関数内で使う変数\n",
    "initial_design = 1     #初期サンプル回数計測\n",
    "try_ = 0               #サンプリング回数計測\n",
    "bounds_list = list()   #パラメータを保存用list\n",
    "\n",
    "#推定用関数\n",
    "\n",
    "def f(x):\n",
    "    model = xgb.XGBClassifier(num_class = 8, \n",
    "                              eta = float(x[:,0]),\n",
    "                              max_depth = int(x[:,1]),\n",
    "                              min_child_weight = float(x[:,2]),\n",
    "                              subsample = float(x[:,3]),\n",
    "                              colsample_bytree = float(x[:,4]),\n",
    "                              gamma = float(x[:,5]),\n",
    "                              n_estimators = int(x[:,6]),\n",
    "                              learning_rate = float(x[:,7]),\n",
    "                              reg_lambda = float(x[:,8]),\n",
    "                              reg_alpha = float(x[:,9]),\n",
    "                              tree_method = 'gpu_hist',\n",
    "                              objective = 'multi:softprob'\n",
    "                              )\n",
    "    #global変数の読み込み\n",
    "    \n",
    "    global initial_design\n",
    "    global try_\n",
    "    global bounds_list\n",
    "    \n",
    "    #回数の表示　Inital_Design:初期　Try:\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Inital_Design:{0} / {1}  Try:{2} / {3}\\n\".format(initial_design, init_num, try_, max_iter))\n",
    "    \n",
    "    #回数の更新\n",
    "    if initial_design < init_num:\n",
    "        initial_design += 1\n",
    "    else:\n",
    "        try_ += 1\n",
    "        \n",
    "    print(\"Next bounds is\")\n",
    "    x = np.reshape(x,(x.size,)) #なぜか(1,10)の二次元配列だったためreshape\n",
    "    \n",
    "    #パラメータの表示\n",
    "    for bound, x_ in zip(bounds, x):\n",
    "        print(f\"{bound['name']:s} = {x_:.3f}  \", end=\"\")\n",
    "    \n",
    "    \n",
    "    x_list = x.tolist() #numpyをlist化(numpyはappendが遅いため)\n",
    "    bounds_list.append(x_list) #パラメータをlistで保存\n",
    "    \n",
    "    # CV\n",
    "    kfold = KFold(n_splits=5, random_state=7)\n",
    "    results = cross_validate(model, train_x, train_y, scoring = 'neg_log_loss', cv=kfold)\n",
    "    \n",
    "    #loglossの表示\n",
    "    score = results['test_score'].mean()*(-1)\n",
    "    print(f\"\\n\\nLogloss: {score:f}\")\n",
    "    \n",
    "    return score\n",
    "\n",
    "bounds = [{'name': 'eta', 'type': 'continuous', 'domain': (0.3,0.4)},\n",
    "          {'name': 'max_depth', 'type': 'continuous', 'domain': (3,15)},\n",
    "          {'name': 'min_child_weight', 'type': 'continuous', 'domain': (0,2)},\n",
    "          {'name': 'subsample', 'type': 'continuous', 'domain': (0.8,1)},\n",
    "          {'name': 'colsample_bytree', 'type': 'continuous', 'domain': (0.8,1)},\n",
    "          {'name': 'gamma', 'type': 'continuous', 'domain': (0,10)},\n",
    "          {'name': 'n_estimators', 'type': 'continuous', 'domain': (10,200)},\n",
    "          {'name': 'learning_rate', 'type': 'continuous', 'domain': (0,1)},\n",
    "          {'name': 'reg_lambda', 'type': 'continuous', 'domain': (0.8,1)},\n",
    "          {'name': 'reg_alpha', 'type': 'continuous', 'domain': (0,0.3)}]\n",
    "\n",
    "print(\"Bayesian Optimization\")\n",
    "myBopt = GPyOpt.methods.BayesianOptimization(f=f,initial_design_numdata=init_num, verbosity = True, domain=bounds)\n",
    "myBopt.run_optimization(max_iter=max_iter)\n",
    "print(\"End\")\n",
    "result_z = myBopt.Y\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### best parameters ###\n",
      "eta = 0.338\n",
      "max_depth = 10.595\n",
      "min_child_weight = 1.051\n",
      "subsample = 0.995\n",
      "colsample_bytree = 0.876\n",
      "gamma = 3.823\n",
      "n_estimators = 63.589\n",
      "learning_rate = 0.252\n",
      "reg_lambda = 0.858\n",
      "reg_alpha = 0.048\n"
     ]
    }
   ],
   "source": [
    "#結果の表示\n",
    "plt.figure()\n",
    "plt.plot(result_z)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"CV Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "#最適なパラメータの表示\n",
    "print(\"### best parameters ###\")\n",
    "\n",
    "for bound, x_opt in zip(bounds, myBopt.x_opt):\n",
    "    print(f\"{bound['name']:s} = {x_opt:.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:37:05] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1588600955503/work/src/learner.cc:328: \n",
      "Parameters: { colsample, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\teval-mlogloss:1.89039\ttrain-mlogloss:1.87977\n",
      "Multiple eval metrics have been passed: 'train-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until train-mlogloss hasn't improved in 10 rounds.\n",
      "[1]\teval-mlogloss:1.78053\ttrain-mlogloss:1.76206\n",
      "[2]\teval-mlogloss:1.70639\ttrain-mlogloss:1.68176\n",
      "[3]\teval-mlogloss:1.65420\ttrain-mlogloss:1.62428\n",
      "[4]\teval-mlogloss:1.61562\ttrain-mlogloss:1.58081\n",
      "[5]\teval-mlogloss:1.58599\ttrain-mlogloss:1.54620\n",
      "[6]\teval-mlogloss:1.56302\ttrain-mlogloss:1.51821\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-36a894d361ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m          'colsample':0.5, 'objective':'multi:softprob','num_class':8, 'eval_metric':'mlogloss'}  \n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevallist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    207\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1247\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1248\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1250\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#最適なパラメータで再度学習、\n",
    "x = myBopt.x_opt\n",
    "dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "dtest = xgb.DMatrix(test_x, label=test_y)  \n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')] \n",
    "num_round = 1000  \n",
    "param = {'eta': x[0],'max_depth':int(x[1]), 'min_child_weight':x[2], 'subsample':x[3],'colsample_bytree':x[4],\n",
    "         'gamma': x[5],'n_estimators':int(x[6]),'learning_rate':x[7],'reg_lambda':x[8],'reg_alpha':x[9],\n",
    "         'colsample':0.5, 'objective':'multi:softprob','num_class':8, 'eval_metric':'mlogloss'}  \n",
    "\n",
    "bst = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77136\n",
      "77136\n",
      "Optimized XGBoost\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred contain different number of classes 8, 2. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [0 1 2 3 4 5 6 7]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-ed58b9bf4855>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimized XGBoost\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   1684\u001b[0m                              \"y_true: {2}\".format(transformed_labels.shape[1],\n\u001b[1;32m   1685\u001b[0m                                                   \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1686\u001b[0;31m                                                   lb.classes_))\n\u001b[0m\u001b[1;32m   1687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m             raise ValueError('The number of classes in labels is different '\n",
      "\u001b[0;31mValueError\u001b[0m: y_true and y_pred contain different number of classes 8, 2. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [0 1 2 3 4 5 6 7]"
     ]
    }
   ],
   "source": [
    "#結果表示\n",
    "pred = Xgb.predict(test_x)\n",
    "pred_p = pd.DataFrame(pred)\n",
    "print(len(pred_p))\n",
    "print(len(test_y))\n",
    "print(\"Optimized XGBoost\")\n",
    "print(log_loss(test_y, pred_p))\n",
    "\n",
    "#重要度の可視化\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib #日本語読み込み\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,25))\n",
    "xgb.plot_importance(bst, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss: 1.434684\n"
     ]
    }
   ],
   "source": [
    "#CVで再学習\n",
    "\n",
    "model = xgb.XGBClassifier(num_class = 8, eta=x[0], max_depth=int(x[1]),min_child_weight=x[2],\n",
    "                          subsample=x[3], colsample_bytree=x[4], gamma=x[5], n_estimators=int(x[6]),\n",
    "                          learning_rate=x[7], reg_lambda=x[8], reg_alpha=x[9],\n",
    "                          tree_method = 'gpu_hist',\n",
    "                          objective = 'multi:softprob',\n",
    "                          \n",
    "                          )\n",
    "\n",
    "# CV\n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=7)\n",
    "results = cross_validate(model, train_x, train_y, scoring = 'neg_log_loss', cv=kfold)\n",
    "score = results['test_score'].mean()*(-1)\n",
    "print(f\"Logloss: {score:f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
