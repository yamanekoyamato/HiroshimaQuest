{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib #日本語読み込み\n",
    "\n",
    "from pandas.plotting import parallel_coordinates\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics  import log_loss\n",
    "\n",
    "import gc　#メモリ開放に使用\n",
    "import pickle #モデル保存に使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "#読み込み\n",
    "train_pitch_df = pd.read_csv(\"../Data/train_pitch_add_column1.csv\")\n",
    "train_player_df = pd.read_csv(\"../Data/train_player.csv\")\n",
    "\n",
    "print(train_pitch_df.columns)\n",
    "train_pitch_df.head()\n",
    "\n",
    "#one-hot化が必要\n",
    "\n",
    "columns1 = ['球場名','試合種別詳細','イニング','表裏','打者打席左右',\n",
    "            '投手投球左右','投手役割','投手登板順','打者打順', '打者守備位置', '1球前ステータス']\n",
    "\n",
    "#one-hot化が必要だが多いので保留\n",
    "columns2 = ['日付', '時刻','年度','試合ID','投手ID','投手チームID','打者ID','打者チームID','プレイ前走者状況',\n",
    "            '一塁走者ID', '二塁走者ID','三塁走者ID', '捕手ID', '一塁手ID', '二塁手ID', '三塁手ID', '遊撃手ID',\n",
    "            '左翼手ID', '中堅手ID','右翼手ID', '成績対象投手ID', '成績対象打者ID','ホームチームID','アウェイチームID','球場ID']\n",
    "\n",
    "#one-hot化が必要なし\n",
    "columns3 = ['試合内連番', '試合内投球数','イニング内打席数', '打席内投球数','投手試合内対戦打者数', '投手試合内投球数',\n",
    "            '投手イニング内投球数','打者試合内打席数', 'プレイ前ホームチーム得点数', 'プレイ前アウェイチーム得点数',\n",
    "            'プレイ前アウト数', 'プレイ前ボール数', 'プレイ前ストライク数','自チーム得点数', '相手チーム得点数', '点差']\n",
    "\n",
    "columns4 = ['データ内連番','球種','投球位置区域']\n",
    "\n",
    "key = ['データ内連番']\n",
    "y1 = ['球種'] #目的変数１\n",
    "y2 = ['投球位置区域'] #目的変数２\n",
    "\n",
    "#指定cloumnのone-hot化\n",
    "train_pitch_df = pd.get_dummies(train_pitch_df, columns = columns1)\n",
    "\n",
    "#余分な特徴量を削除\n",
    "train_pitch_df2 = train_pitch_df.drop(columns = columns2)\n",
    "X = train_pitch_df2.drop(columns = columns4)\n",
    "\n",
    "Y = train_pitch_df['球種']\n",
    "Y2 = train_pitch_df['球種'].astype(str)\n",
    "Y2 = pd.get_dummies(Y2)\n",
    "\n",
    "X.head()\n",
    "\n",
    "#要素ごとの個数を表示\n",
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#要素の偏りをなくしたデータセットの作成\n",
    "\n",
    "Y_X = pd.concat([Y,X],axis = 1)\n",
    "Y_X_10000 = pd.DataFrame()\n",
    "for i in range(8):\n",
    "    tmp = Y_X[Y_X['球種'] == i]\n",
    "    if len(tmp) > 10000:\n",
    "        tmp = tmp[:10000]\n",
    "    else:\n",
    "        tmp = tmp[:len(tmp)]\n",
    "    print(len(tmp))\n",
    "    Y_X_10000 = pd.concat([Y_X_10000, tmp])\n",
    "\n",
    "len(Y_X_10000)\n",
    "X2 = Y_X_10000.drop(columns = [\"球種\"])\n",
    "Y2 = Y_X_10000[\"球種\"]\n",
    "\n",
    "#相関係数\n",
    "Y_X_corr = Y_X.corr()\n",
    "print(type(Y_X_corr))\n",
    "\n",
    "#相関係数のソート\n",
    "#200行まで表示\n",
    "pd.set_option('display.max_rows',200)\n",
    "Y_X_corr_rank = Y_X_corr['球種']\n",
    "Y_X_corr_rank = Y_X_corr.sort_values('球種',ascending=False)\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#メモリの開放\n",
    "del train_pitch_df, train_pitch_df2,train_player_df,tmp,Y_X,Y_X_10000\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通常\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.3, shuffle=True)\n",
    "\n",
    "#球種割合揃え\n",
    "#train_x, test_x, train_y, test_y = train_test_split(X2, Y2, test_size=0.3, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########### XGBoost ###########\n",
    "import xgboost as xgb\n",
    "import GPy\n",
    "import GPyOpt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "'''\n",
    "X：特徴量\n",
    "Y：目的変数\n",
    "必要なもの\n",
    "pip install xgboost\n",
    "pip install japanize-matplotlib\n",
    "'''\n",
    "\n",
    "#変数設定\n",
    "init_num = 50          #初期サンプル数\n",
    "max_iter = 200         #サンプリング回数\n",
    "path_model = \"../Model/xgb_model.pickle\" #Model保存場所\n",
    "\n",
    "#関数内で使う変数\n",
    "initial_design = 1     #初期サンプル回数計測\n",
    "try_ = 0               #サンプリング回数計測\n",
    "bounds_list = list()   #パラメータを保存用list\n",
    "\n",
    "#推定用関数\n",
    "def f(x):\n",
    "    start = time.time()\n",
    "    model = xgb.XGBClassifier(num_class = 8, \n",
    "                              eta = float(x[:,0]),\n",
    "                              max_depth = int(x[:,1]),\n",
    "                              min_child_weight = float(x[:,2]),\n",
    "                              subsample = float(x[:,3]),\n",
    "                              colsample_bytree = float(x[:,4]),\n",
    "                              gamma = float(x[:,5]),\n",
    "                              n_estimators = int(x[:,6]),\n",
    "                              learning_rate = float(x[:,7]),\n",
    "                              reg_lambda = float(x[:,8]),\n",
    "                              reg_alpha = float(x[:,9]),\n",
    "                              tree_method = 'gpu_hist',　　　　　#cpuの場合削除\n",
    "                              objective = 'multi:softprob'\n",
    "                              )\n",
    "    #global変数の読み込み\n",
    "    \n",
    "    global initial_design\n",
    "    global try_\n",
    "    global bounds_list\n",
    "    \n",
    "    #回数の表示　Inital_Design:初期　Try:\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Inital_Design:{0} / {1}  Try:{2} / {3}\\n\".format(initial_design, init_num, try_, max_iter))\n",
    "    \n",
    "    #回数の更新\n",
    "    if initial_design < init_num:\n",
    "        initial_design += 1\n",
    "    else:\n",
    "        try_ += 1\n",
    "        \n",
    "    print(\"Next bounds is\")\n",
    "    x = np.reshape(x,(x.size,)) #なぜか(1,10)の二次元配列だったためreshape\n",
    "    \n",
    "    #パラメータの表示\n",
    "    for bound, x_ in zip(bounds, x):\n",
    "        print(f\"{bound['name']:s} = {x_:.3f}  \", end=\"\")\n",
    "    \n",
    "    \n",
    "    x_list = x.tolist() #numpyをlist化(numpyはappendが遅いため)\n",
    "    bounds_list.append(x_list) #パラメータをlistで保存\n",
    "    \n",
    "    # CV\n",
    "    kfold = KFold(n_splits=5, random_state=7)\n",
    "    results = cross_validate(model, train_x, train_y, scoring = 'neg_log_loss', cv=kfold)\n",
    "    \n",
    "    #時間表示\n",
    "    t = time.time() - start\n",
    "    print(\"\\n\\ntime:\",t)\n",
    "    \n",
    "    #loglossの表示\n",
    "    score = results['test_score'].mean()*(-1)\n",
    "    print(f\"\\nLogloss: {score:f}\")\n",
    "    \n",
    "    \n",
    "    return score\n",
    "\n",
    "bounds = [{'name': 'eta', 'type': 'continuous', 'domain': (0.3,0.4)},\n",
    "          {'name': 'max_depth', 'type': 'continuous', 'domain': (3,15)},\n",
    "          {'name': 'min_child_weight', 'type': 'continuous', 'domain': (0,2)},\n",
    "          {'name': 'subsample', 'type': 'continuous', 'domain': (0.8,1)},\n",
    "          {'name': 'colsample_bytree', 'type': 'continuous', 'domain': (0.8,1)},\n",
    "          {'name': 'gamma', 'type': 'continuous', 'domain': (0,10)},\n",
    "          {'name': 'n_estimators', 'type': 'continuous', 'domain': (10,200)},\n",
    "          {'name': 'learning_rate', 'type': 'continuous', 'domain': (0.3,1)},\n",
    "          {'name': 'reg_lambda', 'type': 'continuous', 'domain': (0.8,1)},\n",
    "          {'name': 'reg_alpha', 'type': 'continuous', 'domain': (0,0.3)}]\n",
    "start_all = time.time()\n",
    "print(\"Bayesian Optimization\")\n",
    "myBopt = GPyOpt.methods.BayesianOptimization(f=f,initial_design_numdata=init_num, verbosity = True, domain=bounds)\n",
    "myBopt.run_optimization(max_iter=max_iter)\n",
    "\n",
    "#処理時間の表示\n",
    "total_time = time.time() - start_all\n",
    "print(\"\\nTotal-Time:\",total_time)\n",
    "\n",
    "print(\"\\nEnd\")\n",
    "result_z = myBopt.Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#結果の可視化\n",
    "plt.figure()\n",
    "plt.plot(result_z)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"CV Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame(bounds_list)\n",
    "for bound ,i in zip(bounds,range(len(bounds))):\n",
    "    df = df.rename(columns={i:bound[\"name\"]})\n",
    "\n",
    "for name, bound_list in df.iteritems():\n",
    "    plt.figure()\n",
    "    plt.plot(bound_list)\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(name)\n",
    "    plt.show()\n",
    "    plt.clf\n",
    "    plt.close()\n",
    "print(len(bounds_list))\n",
    "    \n",
    "#最適なパラメータの表示\n",
    "print(\"### best parameters ###\")\n",
    "\n",
    "for bound, x_opt in zip(bounds, myBopt.x_opt):\n",
    "    print(f\"{bound['name']:s} = {x_opt:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#最適なパラメータで再度学習、\n",
    "#x = myBopt.x_opt\n",
    "x=([3.58159257e-01, 1.31312711e+01, 1.72685680e-01, 8.54364803e-01,\n",
    "       8.01858020e-01, 1.45562823e+00, 1.88617583e+02, 1.12371349e-01,\n",
    "       9.54153925e-01, 2.94973626e-01])\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "dtest = xgb.DMatrix(test_x, label=test_y)  \n",
    "evallist = [(dtrain, 'train'), (dtest, 'eval')]  #saigonosiyhyougaearly_stopnisiyou\n",
    "num_round = 500  \n",
    "\n",
    "param = {'eta': x[0],'max_depth':int(x[1]), 'min_child_weight':x[2], 'subsample':x[3],'colsample_bytree':x[4],\n",
    "         'gamma': x[5],'n_estimators':int(x[6]),'learning_rate':x[7],'reg_lambda':x[8],'reg_alpha':x[9],\n",
    "         'colsample':0.5, 'objective':'multi:softprob','num_class':8, 'eval_metric':'mlogloss', \n",
    "         'terr_method':'gpu_hist'}  #cpuの場合削除\n",
    "\n",
    "bst = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelの保存\n",
    "pickle.dump(bst, open(path_model, \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#結果表示\n",
    "dtest = xgb.DMatrix(test_x, label=test_y)\n",
    "pred = bst.predict(dtest)\n",
    "pred_p = pd.DataFrame(pred)\n",
    "print(len(pred_p))\n",
    "print(len(test_y))\n",
    "print(\"Optimized XGBoost\")\n",
    "print(log_loss(test_y, pred_p))\n",
    "\n",
    "#重要度の可視化\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,25))\n",
    "xgb.plot_importance(bst, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CVで再学習\n",
    "num_round = 500 \n",
    "model = xgb.XGBClassifier(num_class = 8, eta=x[0], max_depth=int(x[1]),min_child_weight=x[2],\n",
    "                          subsample=x[3], colsample_bytree=x[4], gamma=x[5], n_estimators=int(x[6]),\n",
    "                          learning_rate=x[7], reg_lambda=x[8], reg_alpha=x[9],\n",
    "                          tree_method = 'gpu_hist',　　　　　　　#cpuの場合削除\n",
    "                          objective = 'multi:softprob')\n",
    "fit_params = {\"early_stopping_rounds\": 10,\n",
    "              \"eval_set\": [[test_x, test_y]],\n",
    "              'eval_metric':'mlogloss'}\n",
    "\n",
    "# CV\n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=7)\n",
    "results = cross_validate(model, train_x, train_y, fit_params = fit_params, scoring = 'neg_log_loss', cv=kfold)\n",
    "score = results['test_score'].mean()*(-1)\n",
    "print(\"result:\",results['test_score'])\n",
    "print(f\"Logloss: {score:f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#メモリの確認\n",
    "print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n",
    "print(\" ------------------------------------ \")\n",
    "for var_name in dir():\n",
    "    if not var_name.startswith(\"_\"):\n",
    "        print (\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
